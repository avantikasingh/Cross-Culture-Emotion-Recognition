# Cross-Culture-Emotion-Recognition
This is an ongoing project as part of course CSCI 535 Multimodal probabilistic learning for Human Communication.
The project seeks to build a multimodal model capable of recognizing emotions across diverse cultural contexts using varied data inputs, including audio, visual and speech data assessing its effectiveness on datasets representing different cultures

## Dataset
The dataset used is SEWA ( https://db.sewaproject.eu/ )

**Type:** Multimodal dataset (audio, video, physiological signals)
**Number of Samples:** 500,000
**Subjects:** 398 diverse subjects (50% female) with age range of 18 to 65 years old
**Culture:** British, German, Hungarian, Greek, Serbian, and Chinese
**Audio Features:** 20, Video Features: 25 and Physiological Signals: 10
**Missing Values:** Minimal, less than 1% across variables
**Experiment Sessions:** 199
**Audio-Visual Data:** 1525 minutes
**Annotations:** Facial landmarks, vocalizations, valence, arousal, and more


